{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453bfbc2-0d33-4c83-89af-9bad499d1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib\n",
    "import pandas\n",
    "import warnings\n",
    "import requests\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import seaborn\n",
    "import networkx as nx\n",
    "import curatorbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ed3662-2188-4a1f-bb3d-c6528536d112",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "task_id = \"None\"\n",
    "metric_name = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47900d1-9878-4ce5-9dcd-a330d5c33fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_record = requests.get(f\"https://cedar.mongodb.com/rest/v1/perf/task_id/{task_id}\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057f7a5-c2d7-4836-89ba-074c16e78d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [t for t in task_record if metric_name in t[\"info\"][\"test_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ae3e3-028f-4d49-a952-07ca5630437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tests) == 0:\n",
    "    raise ValueError(\"The metric requested does not exist\")\n",
    "\n",
    "metric_record = tests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29bac29-e3af-4830-8389-c377ef57a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_differential_frame(df, dx):\n",
    "    b = pandas.DataFrame()\n",
    "    b[dx] = df[dx]\n",
    "    b[\"d(t_pure)\"] = df[\"d(t_pure)\"]\n",
    "    b[\"d(t_total)\"] = df[\"d(t_total)\"]\n",
    "    b[\"d(t_overhead)\"] = df[\"d(t_overhead)\"]\n",
    "    \n",
    "    b[\"total_latency\"] = b[\"d(t_total)\"] / b[dx]\n",
    "    b[\"overhead_latency\"] = b[\"d(t_overhead)\"] / b[dx]\n",
    "    b[\"pure_latency\"] = b[\"d(t_pure)\"] / b[dx]\n",
    "    b[\"ts\"] = df[\"ts\"]\n",
    "    b[\"actor_id\"] = df[\"actor_id\"]\n",
    "    \n",
    "    # Have a single row for every sample/increment\n",
    "    b = b.loc[b.index.repeat(b[dx])]\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387cfeb7-3e98-47d9-8a66-6a544b8068a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data(result):\n",
    "r = requests.get(metric_record[\"artifacts\"][0][\"download_url\"])\n",
    "with open(f\"{metric_name}.ftdc\", \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "    # try:\n",
    "    #     subprocess.check_call(f\"rm {metric_name}.csv\", shell=True)\n",
    "    # except:\n",
    "    #     pass\n",
    "    # curatorbin.run_curator(\"ftdc\", \"export\", \"csv\", \"--input\", f\"{metric_name}.ftdc\", \"--output\", f\"{metric_name}.csv\")\n",
    "    # # subprocess.check_call(f\"curator ftdc export csv --input ./response2.ftdc --output {metric_name}.csv\", shell=True)\n",
    "    # df = pandas.read_csv(f\"./{metric_name}.csv\")\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791746ca-a4a2-492d-ba1f-e55f4f0f7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    subprocess.check_call(f\"rm {metric_name}.csv\", shell=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7d3318-c529-4551-aa62-f310de83871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curatorbin.run_curator(\"ftdc\", \"export\", \"csv\", \"--input\", f\"{metric_name}.ftdc\", \"--output\", f\"{metric_name}.csv\")\n",
    "# subprocess.check_call(f\"curator ftdc export csv --input ./response2.ftdc --output {metric_name}.csv\", shell=True)\n",
    "# df = pandas.read_csv(f\"./{metric_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
